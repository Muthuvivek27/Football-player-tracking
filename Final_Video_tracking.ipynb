{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ga8kPt_VoqGy"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install pascal-voc-writer\n",
        "!pip install moviepy\n",
        "!pip install natsort"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt"
      ],
      "metadata": {
        "id": "EN3ggGxGotzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Best/best.pt /content/\n",
        "!cp /content/drive/MyDrive/Football_dataset/Video.mp4 /content/"
      ],
      "metadata": {
        "id": "VvJ3u6RUovhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "os.makedirs('/content/Images', exist_ok=True)\n",
        "vidcap = cv2.VideoCapture('/content/Video.mp4')\n",
        "success,image = vidcap.read()\n",
        "count = 0\n",
        "success = True\n",
        "while success:\n",
        "  success,image = vidcap.read()\n",
        "  cv2.imwrite(\"/content/Images/frame%d.jpg\" % count, image)     # save frame as JPEG file\n",
        "  if cv2.waitKey(10) == 27:                     # exit if Escape is hit\n",
        "      break\n",
        "  count += 1"
      ],
      "metadata": {
        "id": "9LXn7XfboyON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/Images/')\n",
        "for filename in os.listdir('/content/Images/'):\n",
        "  os.rename(filename, filename.replace('frame', ''))"
      ],
      "metadata": {
        "id": "gCWi41D5o-o5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MlqrfxtBwOUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import PIL\n",
        "from PIL import Image, ImageDraw,ImageFont\n",
        "import torch\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from pascal_voc_writer import Writer\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import glob\n",
        "from pathlib import Path\n",
        "from sklearn.cluster import KMeans\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from IPython.display import Image, display\n",
        "from sklearn.decomposition import PCA\n",
        "from natsort import natsorted\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#defining model with best weights and defining confidance of 50\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path='/content/best.pt', force_reload=True)\n",
        "model.conf = 0.55\n",
        "\n",
        "#creating cropped folder \n",
        "os.makedirs('/content/Cropped_Images/' , exist_ok=True)\n",
        "\n",
        "a = natsorted(glob.glob('/content/Images/*.jpg'))\n",
        "\n",
        "print(a)\n",
        "\n",
        "filename_predictions = []\n",
        "\n",
        "\n",
        "for i in a:filename_predictions.append(Path(i))\n",
        "\n",
        "print(filename_predictions)\n",
        "for i in filename_predictions:\n",
        "  print(i)\n",
        "  #create a folder for cropped images\n",
        "  os.makedirs('/content/Cropped_Images/'+i.stem + \"/\" , exist_ok=True)\n",
        "  \n",
        "  #predicting the model\n",
        "  results = model(PIL.Image.open(i))\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  #pandas values of bounding box\n",
        "  df=results.pandas().xyxy[0]\n",
        "  df=df.drop(['confidence'],axis=1)\n",
        "  df=df[['class','xmin','xmax','ymin','ymax','name']]\n",
        "  #counting no of bounding box\n",
        "  count_row = df.shape[0]\n",
        "\n",
        "  #reading image details:\n",
        "  im = cv2.imread(i)\n",
        "  height=im.shape[0]\n",
        "  width=im.shape[1]\n",
        "  depth=im.shape[2]\n",
        "\n",
        "  #finding x,y,h,w: of each bounding Box\n",
        "  for j in range(0,count_row):\n",
        "    print(j)\n",
        "    h=df[\"ymax\"].values[j]-df[\"ymin\"].values[j]\n",
        "    w=df[\"xmax\"].values[j]-df[\"xmin\"].values[j]\n",
        "    y=df[\"ymin\"].values[j]\n",
        "    x=df[\"xmin\"].values[j]\n",
        "    \n",
        "    #cropping and saving the file as per number on annotaion\n",
        "    # try:\n",
        "      \n",
        "      #crop = im[int(y+((h-30)/2)):int(y+(h/2)+15), int(x+((w-30)/2)):int((x+(w/2)+15))]\n",
        "    crop = im[int(y+((h-(h*.30))/2)):int(y+(h/2)+((h*.30)/2)), int(x+((w-(w*.30))/2)):int(x+(w/2)+((w*.30)/2))]\n",
        "    # except:\n",
        "    #   print('donkey')\n",
        "    #   crop = im[int(y):int(y+h), int(x):int(x+w)]\n",
        "\n",
        "    #crop =im[int(((y+h)/2)-20):int(((y+h)/2)+20),int(((x+w)/2)-20):int(((x+w)/2)+20)]\n",
        "    #print(f\"x={x},y={y},w={w},h={h}\")\n",
        "    #print(f\"x1={((x+w)/2)-20},y2={((y+h)/2)-20},x2={((x+w)/2)+20},y2={((y+h)/2)+20}\")\n",
        "    cv2.imwrite(\"/content/Cropped_Images/\"+ i.stem + \"/\" + str(j) + \".jpg\",crop)\n",
        "\n",
        "  # relative path to search all jpg files\n",
        "  b = natsorted(glob.glob('/content/Cropped_Images/'+i.stem +'/*.jpg'))\n",
        "  filename_cropped = []\n",
        "  for n in b: filename_cropped.append(Path(n))\n",
        "  \n",
        "  array_1=np.array([])\n",
        "  final=[]\n",
        "  #image Size\n",
        "  IMG_SIZE = 32\n",
        "\n",
        "  #number of clusters \n",
        "  n = 2\n",
        "\n",
        "\n",
        "  #cropped files to be taken for classification\n",
        "  for k in filename_cropped:\n",
        "    I = cv.imread(k)\n",
        "    #to resize the files\n",
        "    width = int(I.shape[1] * 75 / 100)\n",
        "    height = int(I.shape[0] * 75 / 100)\n",
        "    dim = (width, height)\n",
        "    I=cv2.resize(I,(IMG_SIZE,IMG_SIZE))\n",
        "    #storing the image in Numpy arr\n",
        "    a = np.asarray(I,dtype=np.float32)\n",
        "    #normalizing\n",
        "    a = a/255.0\n",
        "    reshaped_data = a.reshape(len(a),-1)\n",
        "    reshaped_data=np.hstack(reshaped_data)\n",
        "    \n",
        "    arr = np.array(reshaped_data)\n",
        "    arr.flatten()\n",
        "    final.append(arr)\n",
        "  #changing list to numpy arr\n",
        "  final=np.array(final)\n",
        "\n",
        "  # #team1_mask = [255, 0, 0] | [255, 255, 255] # replace with a mask for team1's jersey color\n",
        "  # team2_mask = [0, 0, 0]  # replace with a mask for team2's jersey color\n",
        "  # team1_colors = []\n",
        "  # team2_colors = []\n",
        "  # for image in final:\n",
        "  #   team1_pixels = [color for color in image if np.array_equal(color, team1_mask)]\n",
        "  #   team2_pixels = [color for color in image if np.array_equal(color, team2_mask)]\n",
        "  #   team1_color = np.mean(team1_pixels, axis=0)\n",
        "  #   team2_color = np.mean(team2_pixels, axis=0)\n",
        "  #   team1_colors.append(team1_color)\n",
        "  #   team2_colors.append(team2_color)\n",
        "  #df_PCA=pd.DataFrame(final)\n",
        "  #print(df_PCA.shape)\n",
        "  #n_pca = 2  # set the desired number of PCA components\n",
        "  #pca = PCA(n_components=n_pca)\n",
        "  #final = pca.fit_transform(final)\n",
        "\n",
        "  k_means = KMeans(n_clusters=n)\n",
        "  #training a model\n",
        " \n",
        "  # colors = KMeans.cluster_centers_.astype(int)\n",
        "  # print(colors)\n",
        "  if int(i.stem) <=150:\n",
        "    final = np.vstack(final)\n",
        "    model_Team = k_means.fit(final)\n",
        "    print(final.shape)\n",
        "  #colors = k_means.cluster_centers_.astype(int)\n",
        "  \n",
        "  #predicting the images\n",
        "  Final_Lables=model_Team.predict(final)\n",
        "\n",
        "  #naming the lables\n",
        "  lables = ['Team1','Team2','Others']\n",
        "  lables_dic= {0 :'Team1', 1:\"Team2\",2: \"Others\"}\n",
        "  Final_Lables=[lables_dic.get(x, x) for x in Final_Lables]\n",
        "  print(Final_Lables)\n",
        "\n",
        "\n",
        "  \n",
        "  shutil.copy(\"/content/Images/\"+i.stem+\".jpg\",\"/content/Cropped_Images/\")\n",
        "\n",
        "  im=PIL.Image.open(\"/content/Cropped_Images/\"+i.stem+\".jpg\")\n",
        "\n",
        "  for m in range(0,count_row):\n",
        "    h=df[\"ymax\"].values[m]-df[\"ymin\"].values[m]\n",
        "    w=df[\"xmax\"].values[m]-df[\"xmin\"].values[m]\n",
        "    y=df[\"ymin\"].values[m]\n",
        "    x=df[\"xmin\"].values[m]\n",
        "    draw = ImageDraw.Draw(im)\n",
        "    if(Final_Lables[m]=='Team1'):\n",
        "      draw.rectangle((x, y, x+w, y+h), outline=(255, 0, 0),width=2)\n",
        "    elif(Final_Lables[m]=='Team2'):\n",
        "      draw.rectangle((x, y, x+w, y+h), outline=(0, 255, 0),width=2)\n",
        "    elif(Final_Lables[m]=='Others'):\n",
        "      draw.rectangle((x, y, x+w, y+h), outline=(0, 0, 0),width=2)\n",
        "    draw2 = ImageDraw.Draw(im)\n",
        "    draw2.text((x, y),Final_Lables[m])\n",
        "    im.save(\"/content/Cropped_Images/\"+i.stem+\".jpg\")\n",
        "  display(Image(\"/content/Cropped_Images/\"+i.stem+\".jpg\"))\n",
        "  #print(i.stem)"
      ],
      "metadata": {
        "id": "87FGEBV3pL4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os,glob\n",
        "from pathlib import Path\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # FourCC code\n",
        "out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640, 480))\n",
        "a = natsorted(glob.glob('/content/Images/*.jpg'))\n",
        "# Load the images\n",
        "images = []\n",
        "for i in a:images.append(Path(i))\n",
        "# for i in images:\n",
        "#     images.append(cv2.imread(i))\n",
        "\n",
        "# Write the images to the video\n",
        "# for image in images:\n",
        "#   out.write(image)\n",
        "\n",
        "# # Release the VideoWriter\n",
        "# out.release()\n",
        "im = cv2.imread('/content/Images/0.jpg')\n",
        "height=im.shape[0]\n",
        "width=im.shape[1]\n",
        "depth=im.shape[2]\n",
        "print(width,height)"
      ],
      "metadata": {
        "id": "68oT_BIppfJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Create a VideoWriter object\n",
        "output_video = cv2.VideoWriter('/content/output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 30,(width,height ))\n",
        "\n",
        "# Iterate through the images in the directory\n",
        "for filename in natsorted(os.listdir('/content/Cropped_Images/')):\n",
        "    if filename.endswith('.jpg'):\n",
        "        # Read the image\n",
        "        img = cv2.imread(os.path.join('/content/Cropped_Images', filename))\n",
        "        # Resize the image if necessary\n",
        "        img = cv2.resize(img, (width, height))\n",
        "        # Write the image to the video\n",
        "        output_video.write(img)\n",
        "\n",
        "# Release the VideoWriter object\n",
        "output_video.release()"
      ],
      "metadata": {
        "id": "7fKmj_yrpg66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r '/content/Cropped_Images'"
      ],
      "metadata": {
        "id": "Yna1lndz2whf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename_predictions"
      ],
      "metadata": {
        "id": "pI44pf6w3DKm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}